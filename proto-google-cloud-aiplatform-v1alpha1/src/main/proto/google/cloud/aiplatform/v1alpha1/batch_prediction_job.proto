// Copyright 2020 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package google.cloud.aiplatform.v1alpha1;

import "google/api/field_behavior.proto";
import "google/api/resource.proto";
import "google/cloud/aiplatform/v1alpha1/completion_stats.proto";
import "google/cloud/aiplatform/v1alpha1/io.proto";
import "google/cloud/aiplatform/v1alpha1/job_state.proto";
import "google/cloud/aiplatform/v1alpha1/machine_resources.proto";
import "google/protobuf/struct.proto";
import "google/protobuf/timestamp.proto";
import "google/rpc/status.proto";
import "google/api/annotations.proto";

option go_package = "google.golang.org/genproto/googleapis/cloud/aiplatform/v1alpha1;aiplatform";
option java_multiple_files = true;
option java_outer_classname = "BatchPredictionJobProto";
option java_package = "com.google.cloud.aiplatform.v1alpha1";

// A job that uses a [Model][google.cloud.aiplatform.v1alpha1.BatchPredictionJob.model] to produce predictions
// on multiple [input instances][google.cloud.aiplatform.v1alpha1.BatchPredictionJob.input_config]. If
// predictions for significant portion of the instances fail, the job may finish
// without attempting predictions for all remaining instances.
message BatchPredictionJob {
  option (google.api.resource) = {
    type: "aiplatform.googleapis.com/BatchPredictionJob"
    pattern: "projects/{project}/locations/{location}/batchPredictionJobs/{batch_prediction_job}"
  };

  // Configures the input to [BatchPredictionJob][google.cloud.aiplatform.v1alpha1.BatchPredictionJob].
  // See [Model.supported_input_storage_formats][google.cloud.aiplatform.v1alpha1.Model.supported_input_storage_formats] for Model's supported input
  // formats, and how instances should be expressed via any of them.
  message InputConfig {
    // Required. The source of the input.
    oneof source {
      // The Google Cloud Storage location for the input instances.
      GcsSource gcs_source = 2;

      // The BigQuery location of the input table.
      // The schema of the table should be in the format described by the given
      // context OpenAPI Schema, if one is provided. The table may contain
      // additional columns that are not described by the schema, and they will
      // be ignored.
      BigQuerySource bigquery_source = 3;
    }

    // Required. The format in which instances are given, must be one of the
    // [Model's][google.cloud.aiplatform.v1alpha1.BatchPredictionJob.model]
    // [supported_input_storage_formats][google.cloud.aiplatform.v1alpha1.Model.supported_input_storage_formats].
    string instances_format = 1 [(google.api.field_behavior) = REQUIRED];
  }

  // Configures the output of [BatchPredictionJob][google.cloud.aiplatform.v1alpha1.BatchPredictionJob].
  // See [Model.supported_output_storage_formats][google.cloud.aiplatform.v1alpha1.Model.supported_output_storage_formats] for supported output
  // formats, and how predictions are expressed via any of them.
  message OutputConfig {
    // Required. The destination of the output.
    oneof destination {
      // The Google Cloud Storage location of the directory where the output is
      // to be written to. In the given directory a new directory is created.
      // Its name will be "prediction-<model-display-name>-<job-create-time>",
      // where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format.
      // Inside of it files predictions_0001.<extension>,
      // predictions_0002.<extension>, ..., predictions_N.<extension>
      // will be created where <extension> depends on chosen
      // [predictions_format][google.cloud.aiplatform.v1alpha1.BatchPredictionJob.OutputConfig.predictions_format], and N may equal 0001 and depends on the total
      // number of successfully predicted instances.
      // If the Model has both [instance][google.cloud.aiplatform.v1alpha1.PredictSchemata.instance_schema_uri]
      // and [prediction][google.cloud.aiplatform.v1alpha1.PredictSchemata.parameters_schema_uri] schemata
      // defined then each such file will contain predictions as per the
      // [predictions_format][google.cloud.aiplatform.v1alpha1.BatchPredictionJob.OutputConfig.predictions_format].
      // If prediction for any instance failed (partially or completely), then
      // an additional `errors_0001.<extension>`, `errors_0002.<extension>`,...,
      // `errors_N.<extension>` files will be created (N depends on total number
      // of failed predictions). These files will contain the failed instances,
      // as per their schema, followed by an additional `error` field which as
      // value will have
      //
      // [`google.rpc.Status`](https:
      // //github.com/googleapis/googleapis/blob/master/google/rpc/status.proto)
      // containing only `code` and `message` fields.
      // Note: Currently, temporarily, AutoML Models may use a different format
      // and different file names, but will still write to the same directory.
      GcsDestination gcs_destination = 2;

      // The BigQuery project location where the output is to be written to.
      // In the given project a new dataset will be created with name
      // `prediction_<model-display-name>_<job-create-time>`
      // where <model-display-name> will be made
      // BigQuery-dataset-name compatible (e.g. most special characters will
      // become underscores), and timestamp will be in
      // YYYY_MM_DDThh_mm_ss_sssZ "based on ISO-8601" format. In the dataset
      // two tables will be created, `predictions`, and `errors`.
      // If the Model has both [instance][google.cloud.aiplatform.v1alpha1.PredictSchemata.instance_schema_uri]
      // and [prediction][google.cloud.aiplatform.v1alpha1.PredictSchemata.parameters_schema_uri] schemata
      // defined then the tables will have columns as follows: The `predictions`
      // table will contain instances for which the prediction succeeded, it
      // will have columns as per a concatenation of the Model's instance and
      // prediction schemata. The `errors` table will contain rows for which the
      // prediction has failed, it will have instance columns, as per the
      // instance schema, followed by a single "errors" column, which as values
      // will have
      //
      // [`google.rpc.Status`](https:
      // //github.com/googleapis/googleapis/blob/master/google/rpc/status.proto)
      // represented as a STRUCT, and containing only `code` and `message`.
      // Note: Currently, temporarily, AutoML Models may not create exactly the
      // tables with the contents as described above, but they will still create
      // dataset as documented, and write any created tables into it.
      BigQueryDestination bigquery_destination = 3;
    }

    // Required. The format in which AI Platform gives the predictions, must be one of the
    // [Model's][google.cloud.aiplatform.v1alpha1.BatchPredictionJob.model]
    //
    // [supported_output_storage_formats][google.cloud.aiplatform.v1alpha1.Model.supported_output_storage_formats].
    string predictions_format = 1 [(google.api.field_behavior) = REQUIRED];
  }

  // Further describes this job's output.
  // Supplements [output_config][google.cloud.aiplatform.v1alpha1.BatchPredictionJob.output_config].
  message OutputInfo {
    // The output location into which prediction output is written.
    oneof output_location {
      // Output only. The full path of the Google Cloud Storage directory created, into which
      // the prediction output is written.
      string gcs_output_directory = 1 [(google.api.field_behavior) = OUTPUT_ONLY];

      // Output only. The path of the BigQuery dataset created, in bq://projectId.bqDatasetId
      // format, into which the prediction output is written.
      string bigquery_output_dataset = 2 [(google.api.field_behavior) = OUTPUT_ONLY];
    }
  }

  // Output only. Resource name of the BatchPredictionJob.
  string name = 1 [(google.api.field_behavior) = OUTPUT_ONLY];

  // Required. The user-defined name of this BatchPredictionJob.
  string display_name = 2 [(google.api.field_behavior) = REQUIRED];

  // Required. The name of the Model that produces the predictions via this job,
  // must share the same ancestor Location.
  // Starting this job has no impact on any existing deployments of the Model
  // and their resources.
  string model = 3 [
    (google.api.field_behavior) = REQUIRED,
    (google.api.resource_reference) = {
      type: "aiplatform.googleapis.com/Model"
    }
  ];

  // Required. Input configuration of the instances on which predictions are performed.
  // The schema of any single instance may be specified via
  // the [Model's][google.cloud.aiplatform.v1alpha1.BatchPredictionJob.model]
  // [PredictSchemata's][google.cloud.aiplatform.v1alpha1.Model.predict_schemata]
  // [instance_schema_uri][google.cloud.aiplatform.v1alpha1.PredictSchemata.instance_schema_uri].
  InputConfig input_config = 4 [(google.api.field_behavior) = REQUIRED];

  // The parameters that govern the predictions. The schema of the parameters
  // may be specified via the [Model's][google.cloud.aiplatform.v1alpha1.BatchPredictionJob.model]
  // [PredictSchemata's][google.cloud.aiplatform.v1alpha1.Model.predict_schemata]
  // [parameters_schema_uri][google.cloud.aiplatform.v1alpha1.PredictSchemata.parameters_schema_uri].
  google.protobuf.Value model_parameters = 5;

  // Required. The Configuration specifying where output predictions should
  // be written.
  // The schema of any single prediction may be specified as a concatenation
  // of [Model's][google.cloud.aiplatform.v1alpha1.BatchPredictionJob.model]
  // [PredictSchemata's][google.cloud.aiplatform.v1alpha1.Model.predict_schemata]
  // [instance_schema_uri][google.cloud.aiplatform.v1alpha1.PredictSchemata.instance_schema_uri]
  // and
  // [prediction_schema_uri][google.cloud.aiplatform.v1alpha1.PredictSchemata.prediction_schema_uri].
  OutputConfig output_config = 6 [(google.api.field_behavior) = REQUIRED];

  // The config of resources used by the Model during the batch prediction. If
  // the Model [supports][Model.deployment_supported_resources_types]
  // DEDICATED_RESOURCES this config may be provided (and the job will use these
  // resources), if the Model doesn't support AUTOMATIC_RESOURCES, this config
  // must be provided.
  BatchDedicatedResources dedicated_resources = 7;

  // Immutable. Parameters configuring the batch behavior. Currently only applicable when
  // [dedicated_resources][google.cloud.aiplatform.v1alpha1.BatchPredictionJob.dedicated_resources] are used (in other cases AI Platform does
  // the tuning itself).
  ManualBatchTuningParameters manual_batch_tuning_parameters = 8 [(google.api.field_behavior) = IMMUTABLE];

  // Generate explanation along with the batch prediction results.
  //
  // This can only be set to true for AutoML Tables Models, and only when the
  // output destination is BigQuery. When it's true, the batch prediction
  // output will include a column named `feature_attributions`.
  //
  // For AutoML Tables, the value of the `feature_attributions` column is a
  // struct that maps from string to number. The keys in the map are the names
  // of the features. The values in the map are the how much the features
  // contribute to the predicted result. Features are defined as follows:
  // * A scalar column defines a feature of the same name as the column.
  // * A struct column defines multiple features, one feature per leaf field.
  //   The feature name is the fully qualified path for the leaf field,
  //   separated by ".". For example a column `foo` in the format of
  //   {"bar": {"baz": number}, "foz": number} defines two features:
  //   `foo.bar.baz` and `foo.foz`
  //
  // Attributions of each feature is represented as an extra column in the
  // batch prediction output BigQuery table.
  //
  bool generate_explanation = 23;

  // Output only. Information further describing the output of this job.
  OutputInfo output_info = 9 [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. The detailed state of the job.
  JobState state = 10 [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. Only populated when the job's state is JOB_STATE_FAILED or
  // JOB_STATE_CANCELLED.
  google.rpc.Status error = 11 [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. Partial failures encountered.
  // E.g. single files that couldn't be read.
  // This field never exceeds 20 entries.
  // Status details fields contain standard GCP error details.
  repeated google.rpc.Status partial_failures = 12 [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. Information about resources that had been consumed by this job.
  // Provided in real time at best effort basis, as well as a final value
  // once the job completes.
  // Note: This field currently may be not populated for batch predictions that
  // use AutoML Models.
  ResourcesConsumed resources_consumed = 13 [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. Statistics on completed and failed prediction instances.
  CompletionStats completion_stats = 14 [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. Time when the BatchPredictionJob was created.
  google.protobuf.Timestamp create_time = 15 [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. Time when the BatchPredictionJob for the first time entered the
  // `JOB_STATE_RUNNING` state.
  google.protobuf.Timestamp start_time = 16 [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. Time when the BatchPredictionJob entered any of the following states:
  // `JOB_STATE_SUCCEEDED`, `JOB_STATE_FAILED`, `JOB_STATE_CANCELLED`.
  google.protobuf.Timestamp end_time = 17 [(google.api.field_behavior) = OUTPUT_ONLY];

  // Output only. Time when the BatchPredictionJob was most recently updated.
  google.protobuf.Timestamp update_time = 18 [(google.api.field_behavior) = OUTPUT_ONLY];

  // The labels with user-defined metadata to organize BatchPredictionJobs.
  //
  // Label keys and values can be no longer than 64 characters
  // (Unicode codepoints), can only contain lowercase letters, numeric
  // characters, underscores and dashes. International characters are allowed.
  //
  // See https://goo.gl/xmQnxf for more information and examples of labels.
  map<string, string> labels = 19;
}

// Allows manual tuning of batch operations.
message ManualBatchTuningParameters {
  // Immutable. The number of the records (e.g. instances) of the operation given in
  // each batch to a machine replica. Machine type, and size of a single
  // record should be considered when setting this parameter, higher value
  // speeds up the batch operation's execution, but too high value will result
  // in a whole batch not fitting in a machine's memory, and the whole
  // operation will fail.
  // The default value is 4.
  int32 batch_size = 1 [(google.api.field_behavior) = IMMUTABLE];
}
